{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Play with Logistic Regression](https://playground.tensorflow.org/#activation=sigmoid&batchSize=21&dataset=gauss&regDataset=reg-plane&learningRate=0.00001&regularizationRate=0&noise=0&networkShape=1&seed=0.21479&showTestData=false&discretize=true&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\"> Model probabilistyczny </span>\n",
    "Każdy przykład ze zbioru danych $x_i \\in X$ ma przypisaną etykietę $y_i \\in \\{1, \\ldots, K \\}$.\n",
    " <span style=\"color:purple\">Regresja logistyczna </span> jest jednym z klasycznych modeli, który bezpośrednio nadaje się zarówno do klasyfikacji binarnej (dwie klasy: $y_i \\in \\{0,1\\}$), jak i wieloklasowej. \n",
    "Ten model jest o tyle ważny, że stanowi podstawę modeli klasyfikacyjnych opartych o sieci neuronowe. \n",
    "\n",
    "Regresja logistyczna tworzy model probabilistyczny określający prawdopodobieństwo przynależności punktu do poszczególnych klas. \n",
    "W tym modelu chcemy dla każdego punktu wyznaczyć tak zwany rozkład a posteriori $p(1|x_i),\\ldots,p(K|x_i)$ określający przynależność punktu $x_i$ do każdej z $K$ klas. Jako finalną decyzję o klasyfikacji przyjmujemy tę najbardziej prawdopodobną, czyli:\n",
    "\n",
    "$$\n",
    "c(x) = \\arg \\max_{k \\in \\{1, \\dots, K\\}} p(k | x_i).\n",
    "$$\n",
    "\n",
    "Żeby zbudować taki model, musimy sparametryzować prawdopodobieństwa a posteriori, a następnie zbudować funkcję kosztu definiującą kryterium optymalizacyjne. W celu sparametryzowania $p(k|\\cdot)$, określmy moc przyporządkowania punktu $x$ do klasy $k$, wykorzystując model liniowy postaci:\n",
    "\n",
    "$$\n",
    "f_k(x) = w_k^Tx+b_k \\in \\mathbb{R}, \\quad \\text{dla} \\quad k \\in \\{1, \\ldots, K\\}.\n",
    "$$\n",
    "\n",
    "Mając $K$ takich modeli liniowych, możemy wskazać najbardziej prawdopodobną klasę poprzez wyznaczenie największej wartości $f_k(x)$ dla $k \\in \\{1, \\ldots, K\\}$.\n",
    "W celu transformacji tcyh funkcji do prawdopodobieństw wykorzystamy funkcję <span style=\"color:purple\"> softmax </span> postaci:\n",
    "\n",
    "$$\n",
    "p(k|x) = \\frac{\\exp(z_k)}{\\sum_{j=1}^{K}\\exp(z_j)} \\in (0,1),\n",
    "$$\n",
    "\n",
    "gdzie $z_k = f_k(x) = w_k^T + b_k.$\n",
    "\n",
    "W przypadku klasyfikacji binarnej (dwóch klas) musimy jedynie wyznaczyć jedynie $w_1,b_1$, ponieważ wartości  $w_2,b_2$ wyznaczamy korzystajac z definicji prawdopodobieństwa. W tej sytuacji prawdopodobienstwo a posteriori jest zadane za pomocą <span style=\"color:purple\">funkcji sigmoidalnej: </span>\n",
    "$$\n",
    "p(1|x) = \\frac{\\exp(w^Tx+b)}{1+\\exp(w^Tx+b)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład 1: Implementacja funkcji sigmoidalnej oraz softmax i wykresy tych funkcji dla przykładowych danych\n",
    "\n",
    "#### Główne właściwości funkcji sigmoidalnej:\n",
    "- **Zakres wartości**: Funkcja sigmoidalna przekształca dowolną wartość $x$ (od $-\\infty$ do $+\\infty$) na wartość z zakresu $(0, 1)$. Jest to szczególnie użyteczne w zadaniach klasyfikacji binarnej, ponieważ wynik można zinterpretować jako prawdopodobieństwo.\n",
    "  \n",
    "- **Asymptoty**: Funkcja sigmoidalna asymptotycznie zbliża się do $0$ dla bardzo dużych ujemnych wartości $x$ i do $1$ dla bardzo dużych dodatnich wartości $x$.\n",
    "\n",
    "- **Monotoniczność**: Funkcja jest monotoniczna rosnąca, co oznacza, że dla większych wartości $x$ jej wynik będzie zawsze większy.\n",
    "\n",
    "#### Główne właściwości funkcji softmax:\n",
    "- **Zakres wartości**: Każdy wynik funkcji softmax to prawdopodobieństwo, więc funkcja zwraca wartości z przedziału $(0, 1)$. Dodatkowo suma wszystkich prawdopodobieństw (dla wszystkich klas) wynosi 1.\n",
    "  \n",
    "- **Skalowanie**: Wyniki funkcji softmax zależą od relacji między wartościami w wektorze wejściowym. Jeśli jedna wartość w wektorze jest wyraźnie większa od innych, wynik tej klasy będzie bliski 1, a pozostałe wartości bliskie 0.\n",
    "\n",
    "- **Porównanie z funkcją sigmoidalną**: W przypadku klasyfikacji binarnej można użyć funkcji sigmoidalnej, ale w przypadku klasyfikacji wieloklasowej lepsza jest funkcja softmax, ponieważ zapewnia rozdzielenie prawdopodobieństw pomiędzy wszystkie klasy.\n",
    "\n",
    "#### Pytania:\n",
    "1. **Co się stanie z wynikiem funkcji sigmoidalnej, gdy $x \\to +\\infty$ lub $x \\to -\\infty$?**\n",
    "\n",
    "2. **W jakich przypadkach lepiej użyć funkcji sigmoidalnej, a w jakich funkcji softmax?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Softmax function (applied to a vector)\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # Subtracting max for numerical stability\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# Data for plotting\n",
    "x = np.linspace(-10, 10, 400)  # Range of x for sigmoid\n",
    "y_sigmoid = sigmoid(x)  # Sigmoid output for each x\n",
    "\n",
    "# Softmax data (vector of 3 values for comparison)\n",
    "x_softmax_input = np.array([x, np.zeros_like(x), -x])  # Creating 3 input arrays for softmax\n",
    "\n",
    "# Create the plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot sigmoid function\n",
    "ax1.plot(x, y_sigmoid, label='Sigmoid', color='blue')\n",
    "ax1.set_title('Sigmoid Function')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('Sigmoid(x)')\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot softmax function\n",
    "y_softmax = softmax(x_softmax_input)\n",
    "ax2.plot(x, y_softmax[0], label='Softmax Class 1', color='red')\n",
    "ax2.set_title('Softmax Function')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Softmax(x)')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\"> Funkcja kosztu </span>\n",
    "\n",
    "Estymacja modelu regresji logistycznej polega na znalezieniu parametrów $w_k, b_k$ dla wszytskich klas. Standardowa metoda polega na maksymalizacji funkcji wiarygodności $\\prod_{i=1}^N p(y_i|x_i)$. Biorąc logarytm (z minusem) otrzymujemy problem minimalizacji:\n",
    "\n",
    "$$\n",
    "\\text{LR}_{w,b}(X,Y) = -\\log(X,Y) = - \\frac{1}{N} \\sum_{i=1}^N \\log p (y_i|x_i),\n",
    "$$\n",
    "\n",
    "gdzie $w= (w_1, \\ldots, w_K)$, $b = (b_1, \\ldots, b_K)$. W terminologii sieci neuronowych powyższą funkcję nazywa się często <span style=\"color:purple\">entropią krzyżową (z ang. cross-entropy) </span>. Entropia krzyżowa w połączeniu z funkcją softmax stanowi podstawową funkcję kosztu stosowaną w klasyfikacyjnych sieciach neuronowych. \n",
    "\n",
    "### Przykład obliczania funkcji kosztu w regresji logistycznej\n",
    "\n",
    "Załóżmy, że mamy jedną próbkę $x_1$ z etykietą $y_1 = 1$, a model przewiduje $\\hat{p}(y_1 = 1 | x_1) = 0.8$. Wtedy:\n",
    "\n",
    "1. **Obliczenie prawdopodobieństwa**:\n",
    "   - Ponieważ $y_1 = 1$, obliczamy $p(y_1 = 1 | x_1) = 0.8$.\n",
    "\n",
    "2. **Logarytm prawdopodobieństwa**:\n",
    "   - $\\log p(y_1 = 1 | x_1) = \\log(0.8)$.\n",
    "\n",
    "3. **Funkcja kosztu dla tej próbki**:\n",
    "   - Funkcja kosztu wyniesie:  \n",
    "   $$\n",
    "   - \\log(0.8) \\approx 0.223\n",
    "   $$\n",
    "\n",
    "Jeśli etykieta $y_1$ byłaby 0, a model przewidywał $\\hat{p}(y_1 = 1 | x_1) = 0.8$, wtedy:\n",
    "\n",
    "1. **Obliczenie prawdopodobieństwa**:\n",
    "   - Ponieważ $y_1 = 0$, obliczamy $p(y_1 = 0 | x_1) = 1 - 0.8 = 0.2$.\n",
    "\n",
    "2. **Logarytm prawdopodobieństwa**:\n",
    "   - $\\log p(y_1 = 0 | x_1) = \\log(0.2)$.\n",
    "\n",
    "3. **Funkcja kosztu dla tej próbki**:\n",
    "   - Funkcja kosztu wyniesie:  \n",
    "   $$\n",
    "   - \\log(0.2) \\approx 1.609\n",
    "   $$\n",
    "\n",
    "### Podsumowanie:\n",
    "\n",
    "Funkcja kosztu oblicza, jak dobrze model przewiduje prawdziwe etykiety. Im większa wartość prawdopodobieństwa, tym mniejsza wartość funkcji kosztu, a im bardziej model się myli, tym wyższa wartość funkcji kosztu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład 2.\n",
    "\n",
    "Implementacja regresji logistycznej w PyTorchu.\n",
    "1. Funkcja kosztu modelu regresji logistycznej `loss(X, y)`, zaimplementowana według następujących kroków:\n",
    "    * Obliczenie modelu liniowego $z = w^Tx + b$\n",
    "    * Na wektorze $z$ implementacja funkcji $\\hat{y} = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}$.\n",
    "    * Obliczenie entropii krzyżowej pomiędzy predykcjami $\\hat{y}$ a etykietami $y$ zadaną przez:\n",
    "    $\\frac{1}{N} \\sum_i - (1 - y_i) \\ln (1 - \\hat{y}_i) - y_i \\ln \\hat{y}_i$\n",
    "2. Funkcja `predict_proba(X)` zwracającą dla każdego $x_i \\in X$ zadane przez nasz model prawdopodobieństwo $\\hat{p}(y = 1 \\mid x_i)$. \n",
    "3. Funkcja `predict(X)` zwracającą dla każdego $x_i \\in X$ przewidywaną etykietę (tzn. $0$ albo $1$).\n",
    "\n",
    "**UWAGA** Nie korzystamy tutaj z funkcji PyTorcha do liczenia entropii krzyżowej (np. `torch.nn.BCELoss`) ani sigmoidy (np.`torch.nn.functional.Sigmoid`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Must be using Python 3\")\n",
    "elif sys.version_info[1] < 7:\n",
    "    Dataset = namedtuple(\n",
    "        \"Dataset\",\n",
    "        [\"data\", \"target\", \"target_names\", \"filename\"],\n",
    "    )\n",
    "    Dataset.__new__.__defaults__ = (None,) * len(Dataset._fields)\n",
    "else:\n",
    "    Dataset = namedtuple(\n",
    "        \"Dataset\", [\"data\", \"target\", \"target_names\", \"filename\"], defaults=(None, None, None, None)\n",
    "    )\n",
    "\n",
    "def get_classification_dataset_1d() -> Dataset:\n",
    "    torch.manual_seed(8)\n",
    "    X = torch.cat(\n",
    "        [\n",
    "            torch.randn(10, 1) * 3 + 10,\n",
    "            torch.randn(10, 1) * 3 + 1,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = torch.cat([torch.zeros(10), torch.ones(10)])\n",
    "    return Dataset(X, y)\n",
    "\n",
    "\n",
    "def get_classification_dataset_2d() -> Dataset:\n",
    "    torch.manual_seed(4)\n",
    "    X = torch.cat(\n",
    "        [\n",
    "            torch.randn(50, 2) * 2 + torch.tensor([4.0, 2.0]),\n",
    "            torch.randn(50, 2) * 0.5 + torch.tensor([2.0, -4.0]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = torch.cat([torch.zeros(50), torch.ones(50)])\n",
    "    return Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotujmy datasety i funkcje pomocnicze\n",
    "dataset_1d = get_classification_dataset_1d()\n",
    "dataset_2d = get_classification_dataset_2d()\n",
    "\n",
    "\n",
    "def calculate_accuracy(\n",
    "    logistic_reg: \"LogisticRegression\", X: torch.Tensor, y: torch.Tensor\n",
    ") -> float:\n",
    "    preds = logistic_reg.predict(X)\n",
    "    correct_n = (preds == y).float().sum().item()\n",
    "    return float(correct_n / len(y))\n",
    "\n",
    "\n",
    "def plot_dataset_1d(logistic_reg: \"LogisticRegression\", dataset_1d: Dataset) -> None:\n",
    "    plt.scatter(dataset_1d.data[:10], [0.5] * 10, c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_1d.data[10:], [0.5] * 10, c=\"yellow\", label=\"1\")\n",
    "    linspace = torch.linspace(-7.5, 15, steps=100).view(-1, 1)\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        logistic_reg.predict_proba(linspace).detach().numpy(),\n",
    "        label=\"p(y=1 | x)\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_dataset_2d(logistic_reg: \"LogisticRegression\", dataset_2d: Dataset) -> None:\n",
    "    plt.scatter(dataset_2d.data[:50, 0], dataset_2d.data[:50, 1], c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_2d.data[50:, 0], dataset_2d.data[50:, 1], c=\"yellow\", label=\"1\")\n",
    "\n",
    "    linspace_x = torch.linspace(-4, 7, steps=100)\n",
    "    linspace_y = (-logistic_reg.bias - logistic_reg.weight[0] * linspace_x) / logistic_reg.weight[1]\n",
    "\n",
    "    linspace_y = linspace_y.detach().numpy()\n",
    "    plt.plot(linspace_x.detach().numpy(), linspace_y, label=\"Granica decyzyjna\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, input_dim: int) -> None:\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = torch.randn(self.input_dim, requires_grad=True)\n",
    "        self.bias = torch.randn((), requires_grad=True)\n",
    "\n",
    "    def _sigmoid(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def fit(\n",
    "        self, X: torch.Tensor, y: torch.Tensor, lr: float = 1e-6, num_steps: int = int(1e4)\n",
    "    ) -> None:\n",
    "        self.weight = torch.randn(self.input_dim, requires_grad=True)\n",
    "        self.bias = torch.randn((), requires_grad=True)\n",
    "        for idx in range(num_steps):\n",
    "            self.weight.requires_grad = True\n",
    "            self.bias.requires_grad = True\n",
    "\n",
    "            loss_val = self.loss(X, y)\n",
    "            loss_val.backward()\n",
    "\n",
    "            w_grad = self.weight.grad\n",
    "            b_grad = self.bias.grad\n",
    "            with torch.no_grad():\n",
    "                self.weight = self.weight - lr * w_grad\n",
    "                self.bias = self.bias - lr * b_grad\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 / (1 + torch.exp( -(X @ self.weight + self.bias)))\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.FloatTensor:\n",
    "        return ((self._sigmoid(X @ self.weight + self.bias))>=0.5).float()\n",
    "\n",
    "    def loss(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        y_hat = self._sigmoid(X @ self.weight + self.bias)\n",
    "        return(-(1 - y) * torch.log(1 - y_hat) - y * torch.log(y_hat)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(1)\n",
    "logistic_reg.fit(dataset_1d.data, dataset_1d.target, lr=1e-3, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_1d.data, dataset_1d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_1d(logistic_reg, dataset_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(2)\n",
    "logistic_reg.fit(dataset_2d.data, dataset_2d.target, lr=1e-2, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_2d.data, dataset_2d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_2d(logistic_reg, dataset_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\"> Minimalizacja gradientowa - gradient descent </span>\n",
    "Minimalizacja gradientowa <span style=\"color:purple\">(ang. Gradient Descent, DG)</span> to jedna z najczęściej używanych technik optymalizacji, która polega na iteracyjnym poszukiwaniu minimum funkcji kosztu (straty). Metoda ta jest fundamentalna w kontekście uczenia maszynowego i głębokiego uczenia, szczególnie w kontekście algorytmów takich jak regresja logistyczna czy sieci neuronowe. \n",
    "\n",
    "Celem minimalizacji gradientowej jest znalezienie takich wartości parametrów (wag), które minimalizują funkcję kosztu, czyli błędy predykcji modelu w stosunku do rzeczywistych danych. Działanie tej metody polega na obliczeniu gradientu funkcji kosztu względem wag modelu, a następnie „kroczymy” w kierunku przeciwnym do gradientu, aby zmniejszyć wartość funkcji kosztu. \n",
    "\n",
    "<span style=\"color:purple\">Kroki algorytmu minimalizacji gradientowej</span>.\n",
    "\n",
    "1. **Inicjalizacja wag**:  \n",
    "   Wagi (parametry modelu) są inicjowane losowo.\n",
    "\n",
    "2. **Obliczenie gradientu**:  \n",
    "   Dla bieżących wag, obliczamy gradient funkcji kosztu, czyli zestawienie wszystkich jej pochodnych cząstkowych. Gradient to wektor, który wskazuje kierunek, w którym funkcja kosztu rośnie najszybciej.\n",
    "\n",
    "3. **Aktualizacja wag**:  \n",
    "   Wagi są aktualizowane poprzez „krok” w kierunku przeciwnym do gradientu:\n",
    "   \n",
    "   $$\n",
    "   w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot \\nabla J(w)\n",
    "   $$\n",
    "   \n",
    "   gdzie:\n",
    "   - $ w_{\\text{new}} $ to nowe wagi,\n",
    "   - $ w_{\\text{old}} $ to obecne wagi,\n",
    "   - $ \\eta $ to współczynnik uczenia (learning rate),\n",
    "   - $\\nabla J(w)$ to gradient funkcji kosztu $ J $ względem wag $ w $.\n",
    "\n",
    "4. **Powtarzanie**:  \n",
    "   Proces ten jest powtarzany przez określoną liczbę iteracji lub do momentu, gdy zmiany wag staną się minimalne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\">Uwaga</span>\n",
    "Wybór punktu startowego oraz współczynnika uczenia (learning rate) ma znaczenie dla działania algorytmu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład 3.\n",
    "\n",
    "Uzupełnij implementację algorytmu minimalizacji gradientowej oraz sprawdź, jak różne wartości współczynnika uczenia wpływają na działanie algorytmu.\n",
    "Twoim celem jest zminimalizowanie funkcji $f(x) = x^2 $ za pomocą algorytmu gradient descent.\n",
    "\n",
    "W tym celu należy wykonać następujące kroki:\n",
    "\n",
    "1. Napisać funkcję $ f(x) = x^2 $, która będzie reprezentować nasz obiekt do minimalizacji.\n",
    "2. Obliczyć pochodną tej funkcji.\n",
    "3. Uzupełnić implemnetację algorytmu gradient descent (tylko krok w którym aktualizujemy wagi)\n",
    "\n",
    "\n",
    "Po zaimplementowaniu algorytmu, spróbuj różnych wartości $lr$ (np. 0.01, 0.1, 0.5, 0.9, 1) i sprawdź, jak zmienia się trajektoria i szybkość zbieności algorytmu.\n",
    "\n",
    "Jak współczynnik uczenia wpływa na wynik końcowy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja, którą chcemy minimalizować za pomocą GD\n",
    "def f(x):\n",
    "    ...\n",
    "\n",
    "# Pochodna tej funkcji\n",
    "def df(x):\n",
    "    ...\n",
    "\n",
    "# Implementacja algorytmu minimalizacji gradientowej\n",
    "def gradient_descent(starting_point, learning_rate, iterations):\n",
    "    x = starting_point\n",
    "    trajectory = [x] # lista, która będzie przechowywać kolejne wrtości, zainicjalizowana z punktem startowym\n",
    "    for _ in range(iterations):\n",
    "        ...\n",
    "\n",
    "\n",
    "\n",
    "x_vals = np.linspace(-2, 2, 400)\n",
    "y_vals = f(x_vals)\n",
    "\n",
    "# Parametry minimalizacji gradientowej\n",
    "iterations = 20\n",
    "starting_point = 2  \n",
    "\n",
    "# Różne wartości współczynnika uczenia\n",
    "learning_rate_small = 0.1  \n",
    "learning_rate_large = 0.9  \n",
    "\n",
    "# Obliczanie trajektorii dla obu wartości LR\n",
    "trajectory_small = gradient_descent(starting_point, learning_rate_small, iterations)\n",
    "trajectory_large = gradient_descent(starting_point, learning_rate_large, iterations)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axs[0].plot(x_vals, y_vals, label=\"Funkcja f(x) = x^2\", color=\"blue\", linestyle=\"--\")\n",
    "axs[0].plot(trajectory_small, f(np.array(trajectory_small)), label=f\"Trajektoria (LR = {learning_rate_small} )\", color=\"red\", marker='o')\n",
    "axs[0].set_title(\"Minimalizacja gradientowa\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"f(x)\")\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x_vals, y_vals, label=\"Funkcja f(x) = x^2\", color=\"blue\", linestyle=\"--\")\n",
    "axs[1].plot(trajectory_large, f(np.array(trajectory_large)), label=f\"Trajektoria (LR = {learning_rate_large})\", color=\"green\", marker='o')\n",
    "axs[1].set_title(\"Minimalizacja gradientowa\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"f(x)\")\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4.\n",
    "\n",
    "Wykorzystując zaimplementowany algorytm minimalizacji gradientowej z poprzedniego zadania sprawdź, jak wybór punktu początkowego wpływa na działanie algorytmu.\n",
    "Twoim celem jest zminimalizowanie funkcji $f(x) = x^4 - 4 \\cdot x^3 + 3 \\cdot x^2 $ za pomocą algorytmu gradient descent.\n",
    "\n",
    "W tym celu należy wykonać następujące kroki:\n",
    "\n",
    "1. Napisać funkcję $ f(x) = x^4 - 4 \\cdot x^3 + 3 \\cdot x^2 $, która będzie reprezentować nasz obiekt do minimalizacji.\n",
    "2. Obliczyć pochodną tej funkcji.\n",
    "3. Wykonać algorytm gradient descent zaimplementowany w poprzednim zadaniu.\n",
    "4. Spróbuj różnych wartości punktu początkowego i sprawdź, jak zmienia się zbieżność algorytmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja, którą chcemy minimalizować za pomocą GD\n",
    "def f(x):\n",
    "    ...\n",
    "\n",
    "# Pochodna tej funkcji\n",
    "def df(x):\n",
    "    ...\n",
    "\n",
    "x_vals = np.linspace(-1, 3, 400)\n",
    "y_vals = f(x_vals)\n",
    "\n",
    "# Parametry minimalizacji gradientowej\n",
    "learning_rate = 0.01\n",
    "iterations = 30\n",
    "\n",
    "# Punkty startowe dla dwóch różnych trajektorii\n",
    "starting_point_1 = -1  \n",
    "starting_point_2 = 3  \n",
    "\n",
    "# Obliczanie trajektorii dla obu punktów startowych\n",
    "trajectory_1 = gradient_descent(starting_point_1, learning_rate, iterations)\n",
    "trajectory_2 = gradient_descent(starting_point_2, learning_rate, iterations)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "\n",
    "axs[0].plot(x_vals, y_vals, label=\"Funkcja f(x)\", color=\"blue\")\n",
    "axs[0].plot(trajectory_1, f(np.array(trajectory_1)), label=f\"Trajektoria (start {starting_point_1})\", color=\"red\", marker='o')\n",
    "axs[0].set_title(\"Minimum lokalne\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"f(x)\")\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x_vals, y_vals, label=\"Funkcja f(x)\", color=\"blue\")\n",
    "axs[1].plot(trajectory_2, f(np.array(trajectory_2)), label=f\"Trajektoria (start {starting_point_2})\", color=\"green\", marker='o')\n",
    "axs[1].set_title(\"Minimum globalne\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"f(x)\")\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład 5.\n",
    "Implementacja modelu regresji logistycznej z wykorzystaniem biblioteki sklearn i wizualizacja granicy decyzyjnej w przestrzeni cech dla danych dwuwymiarowych.\n",
    "\n",
    "Sprawdź, jak zmienia się granica decyzyjna w zależności od różnych parametrów modelu (np. dodania regularizacji lub zmiany rozkładu danych).\n",
    "Podpowiedź:\n",
    "Do wizualizacji granicy decyzyjnej możesz użyć siatki punktów w przestrzeni cech:\n",
    "- wygeneruj siatkę za pomocą np.meshgrid,\n",
    "- dla każdego punktu na siatce oblicz przewidywane prawdopodobieństwo $p(y=1∣x)$,\n",
    "- narysuj linię odpowiadającą $p(y=1∣x)=0.5.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=200, centers=2, random_state=42, cluster_std=2.0)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 200),\n",
    "                     np.linspace(X[:, 1].min()-1, X[:, 1].max()+1, 200))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = model.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolor='k', alpha=0.7)\n",
    "plt.contour(xx, yy, probs, levels=[0.5], colors='black', linewidths=2)  # Granica decyzyjna\n",
    "plt.title(\"Granica decyzyjna regresji logistycznej\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dane z różnym odchyleniem standardowym\n",
    "X1, y1 = make_blobs(n_samples=200, centers=2, random_state=42, cluster_std=4.0)  # Większy rozrzut\n",
    "X2, y2 = make_blobs(n_samples=200, centers=2, random_state=42, cluster_std=0.5)  # Mniejszy rozrzut\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dodanie nieliniowych cech\n",
    "X_nl = np.c_[X1, X1[:, 0] ** 2, X1[:, 0] * X1[:, 1]]  # Dodanie cechy x^2 i xy\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
